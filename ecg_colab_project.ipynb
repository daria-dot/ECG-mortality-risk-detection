{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA2vDD6n+/5AOCrTQg+s7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daria-dot/ECG-mortality-risk-detection/blob/main/ecg_colab_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmde6aJU8GaV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Phase 1: Data Loading & Environment Setup (Google Colab)\\n\\nThis notebook walks you through all the steps for Phase 1\n",
        "#of our hackathon project.\n",
        "#We will:  Set up the Google Colab environment and connect Google Drive.\\n2.  Download the `exams.csv`\n",
        "#label file from the `CODE-15%` dataset.\n",
        "#  Load the labels into a `pandas` DataFrame.\\n4.  Download the **first part** of the large HDF5\n",
        "#ECG data to create a data-loading function.\\n5.\n",
        "# Inspect the HDF5 data to confirm its shape and format.\n",
        "# Explain how to save this notebook to your new GitHub repo.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y10YsgdF8plE",
        "outputId": "bd9a99f9-2b23-4dc5-df94-b55e4eeb7c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (3.15.1)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from h5py) (2.0.2)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=7acd6f268633b6870f4ee9e1279441ed24e9695aad08e6a61d4c43ff4e092d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install h5py, the library needed to read HDF5 files\n",
        "!pip install h5py\n",
        "\n",
        "# Import all the libraries we'll need\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "import glob # This will help us find all our zip files\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "klj_JnJp9elh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00fb874-902b-44ea-f3d8-35324dd08db2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from h5py) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the command that connects to your Drive\n",
        "# A pop-up will ask for your permission.\n",
        "print(\"Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive connected!\")"
      ],
      "metadata": {
        "id": "H2qlwzK9A08S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee877f2-16c0-4691-ce2a-6dcc5861b535"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive connected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVE_PROJECT_PATH = '/content/drive/MyDrive/ecg-colab-project'\n",
        "# ---\n",
        "# These paths are built from the main path\n",
        "LABELS_CSV_PATH = os.path.join(GDRIVE_PROJECT_PATH, 'exams.csv')\n",
        "HDF5_DATA_DIR = os.path.join(GDRIVE_PROJECT_PATH, 'hdf5_data')"
      ],
      "metadata": {
        "id": "NwziJlsdFui-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Loading labels from exams.csv...\")\n",
        "df_labels = pd.read_csv(LABELS_CSV_PATH)\n",
        "\n",
        "# Display the first 5 rows to confirm it loaded\n",
        "print(\"--- First 5 rows of exams.csv ---\")\n",
        "print(df_labels.head())\n",
        "\n",
        "# Display info to confirm we see 'death' and 'timey'\n",
        "print(\"\\n--- DataFrame Info ---\")\n",
        "df_labels.info()\n",
        "\n",
        "print(f\"\\nExams with mortality data: {df_labels['death'].notna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9Oe-TRNGKi7",
        "outputId": "e52f0df2-be4c-4b16-d7bc-2693f4570184"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading labels from exams.csv...\n",
            "--- First 5 rows of exams.csv ---\n",
            "   exam_id  age  is_male  nn_predicted_age  1dAVb   RBBB   LBBB     SB     ST  \\\n",
            "0  1169160   38     True         40.160484  False  False  False  False  False   \n",
            "1  2873686   73     True         67.059440  False  False  False  False  False   \n",
            "2   168405   67     True         79.621740  False  False  False  False  False   \n",
            "3   271011   41     True         69.750260  False  False  False  False  False   \n",
            "4   384368   73     True         78.873460  False  False  False  False  False   \n",
            "\n",
            "      AF  patient_id  death     timey  normal_ecg         trace_file  \n",
            "0  False      523632  False  2.098628        True  exams_part13.hdf5  \n",
            "1  False     1724173  False  6.657529       False  exams_part13.hdf5  \n",
            "2   True       51421  False  4.282188       False  exams_part13.hdf5  \n",
            "3  False     1737282  False  4.038353        True  exams_part13.hdf5  \n",
            "4  False      331652  False  3.786298       False  exams_part13.hdf5  \n",
            "\n",
            "--- DataFrame Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 345779 entries, 0 to 345778\n",
            "Data columns (total 15 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   exam_id           345779 non-null  int64  \n",
            " 1   age               345779 non-null  int64  \n",
            " 2   is_male           345779 non-null  bool   \n",
            " 3   nn_predicted_age  345779 non-null  float64\n",
            " 4   1dAVb             345779 non-null  bool   \n",
            " 5   RBBB              345779 non-null  bool   \n",
            " 6   LBBB              345779 non-null  bool   \n",
            " 7   SB                345779 non-null  bool   \n",
            " 8   ST                345779 non-null  bool   \n",
            " 9   AF                345779 non-null  bool   \n",
            " 10  patient_id        345779 non-null  int64  \n",
            " 11  death             233647 non-null  object \n",
            " 12  timey             233647 non-null  float64\n",
            " 13  normal_ecg        345779 non-null  bool   \n",
            " 14  trace_file        345779 non-null  object \n",
            "dtypes: bool(8), float64(2), int64(3), object(2)\n",
            "memory usage: 21.1+ MB\n",
            "\n",
            "Exams with mortality data: 233647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#currently only have 1 zip file but will keep loop for potential later developments\n",
        "\n",
        "print(f\"Looking for .zip files in: {HDF5_DATA_DIR}\")\n",
        "zip_files = glob.glob(os.path.join(HDF5_DATA_DIR, \"*.zip\"))\n",
        "zip_files.sort()\n",
        "\n",
        "if not zip_files:\n",
        "    print(\"No .zip files found. Are they in the right folder?\")\n",
        "else:\n",
        "    print(f\"Found {len(zip_files)} zip files. Starting unzip process...\")\n",
        "\n",
        "# Loop over each zip file and unzip it\n",
        "for file_path in zip_files:\n",
        "    print(f\"Unzipping {os.path.basename(file_path)}...\")\n",
        "\n",
        "    # -q (quiet), -o (overwrite), -d (destination)\n",
        "    !unzip -q -o \"{file_path}\" -d \"{HDF5_DATA_DIR}\"\n",
        "\n",
        "    print(f\"Finished unzipping {os.path.basename(file_path)}\")\n",
        "\n",
        "print(\"All files unzipped!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6BGJ__tGi7w",
        "outputId": "ea0f06a2-af91-4669-877c-42cf603dfeb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for .zip files in: /content/drive/MyDrive/ecg-colab-project/hdf5_data\n",
            "Found 1 zip files. Starting unzip process...\n",
            "Unzipping exams_part0.zip...\n",
            "Finished unzipping exams_part0.zip\n",
            "All files unzipped!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll just check the first HDF5 file\n",
        "PART0_HDF5_PATH = os.path.join(HDF5_DATA_DIR, 'exams_part0.hdf5')\n",
        "\n",
        "print(f\"Opening HDF5 file at: {PART0_HDF5_PATH}\")\n",
        "\n",
        "try:\n",
        "    with h5py.File(PART0_HDF5_PATH, 'r') as hf:\n",
        "        # HDF5 files are like dictionaries. Let's see the keys.\n",
        "        print(\"Keys in the HDF5 file:\", list(hf.keys()))\n",
        "\n",
        "        # Get the 'tracings' dataset (this is the ECG data)\n",
        "        tracings = hf['tracings']\n",
        "        # Get the 'exam_id' dataset (this links tracings to our CSV)\n",
        "        exam_ids_hdf5 = hf['exam_id']\n",
        "\n",
        "        print(\"\\n--- Dataset Shapes ---\")\n",
        "        print(f\"Tracings dataset shape: {tracings.shape} (Exams, Samples, Leads)\")\n",
        "        print(f\"Exam IDs dataset shape: {exam_ids_hdf5.shape}\")\n",
        "\n",
        "        # --- Load one sample ECG ---\n",
        "        print(\"\\n--- Loading One Sample ECG ---\")\n",
        "        sample_exam_id = exam_ids_hdf5[0]\n",
        "        sample_ecg_tracing = tracings[0] # Load the first ECG\n",
        "\n",
        "        print(f\"Loaded ECG for exam_id: {sample_exam_id}\")\n",
        "        print(f\"ECG data shape: {sample_ecg_tracing.shape}\")\n",
        "\n",
        "        # Verify it matches the expected shape (4096 samples, 12 leads)\n",
        "        assert sample_ecg_tracing.shape == (4096, 12)\n",
        "\n",
        "        print(\"\\n--- PHASE 1 COMPLETE! ---\")\n",
        "        print(\"Data is in Google Drive, unzipped, and readable.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred. Did Step 4 (unzip) fail? Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEkjKebCHQpb",
        "outputId": "7946f0f9-61a7-4f5f-bc58-a8c834a7ea29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening HDF5 file at: /content/drive/MyDrive/ecg-colab-project/hdf5_data/exams_part0.hdf5\n",
            "Keys in the HDF5 file: ['exam_id', 'tracings']\n",
            "\n",
            "--- Dataset Shapes ---\n",
            "Tracings dataset shape: (20001, 4096, 12) (Exams, Samples, Leads)\n",
            "Exam IDs dataset shape: (20001,)\n",
            "\n",
            "--- Loading One Sample ECG ---\n",
            "Loaded ECG for exam_id: 590673\n",
            "ECG data shape: (4096, 12)\n",
            "\n",
            "--- PHASE 1 COMPLETE! ---\n",
            "Data is in Google Drive, unzipped, and readable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "da0o2dJVI6zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 2: Pre-Processing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WYmaAzBLI0z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Original leads from CODE-15% (all 12)\n",
        "# Indices: 0   1    2     3     4     5    6   7   8   9   10  11\n",
        "LEADS_ALL = ['DI','DII','DIII','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6']\n",
        "\n",
        "# Leads required by the Lancet paper (8)\n",
        "LEADS_REQUIRED = ['DI','DII','V1','V2','V3','V4','V5','V6']\n",
        "\n",
        "# This line of code automatically finds the correct indices\n",
        "LEAD_INDICES = [LEADS_ALL.index(lead) for lead in LEADS_REQUIRED]\n",
        "\n",
        "print(f\"Original number of leads: {len(LEADS_ALL)}\")\n",
        "print(f\"Required number of leads: {len(LEADS_REQUIRED)}\")\n",
        "print(f\"Column indices to keep: {LEAD_INDICES}\")\n",
        "\n",
        "# The output should be: [0, 1, 6, 7, 8, 9, 10, 11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GWEJde7IntH",
        "outputId": "fd6b07de-bf6d-47c3-b189-a0580f0414a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of leads: 12\n",
            "Required number of leads: 8\n",
            "Column indices to keep: [0, 1, 6, 7, 8, 9, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll re-use the HDF5 file path from Phase 1\n",
        "# (Make sure you've run the cell that defines HDF5_DATA_DIR)\n",
        "PART0_HDF5_PATH = os.path.join(HDF5_DATA_DIR, 'exams_part0.hdf5')\n",
        "\n",
        "print(f\"Opening HDF5 file: {PART0_HDF5_PATH}\")\n",
        "\n",
        "try:\n",
        "    with h5py.File(PART0_HDF5_PATH, 'r') as hf:\n",
        "        # Load the first ECG tracing from the file\n",
        "        sample_ecg_12_lead = hf['tracings'][0]\n",
        "\n",
        "        print(f\"Original ECG shape: {sample_ecg_12_lead.shape}\")\n",
        "\n",
        "        # --- THIS IS THE PRE-PROCESSING STEP ---\n",
        "        # We use numpy indexing to select only the columns (leads) we want\n",
        "        sample_ecg_8_lead = sample_ecg_12_lead[:, LEAD_INDICES]\n",
        "        # ---\n",
        "\n",
        "        print(f\"Processed ECG shape: {sample_ecg_8_lead.shape}\")\n",
        "\n",
        "        # Verify it matches the expected shape (4096, 8)\n",
        "        assert sample_ecg_8_lead.shape == (4096, 8)\n",
        "\n",
        "        print(\"\\n--- PHASE 2 COMPLETE! ---\")\n",
        "        print(\"We can successfully pre-process a 12-lead ECG into an 8-lead one.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGhR1zPItcf",
        "outputId": "e6aa6a01-3ece-4a82-e659-140199405e94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening HDF5 file: /content/drive/MyDrive/ecg-colab-project/hdf5_data/exams_part0.hdf5\n",
            "Original ECG shape: (4096, 12)\n",
            "Processed ECG shape: (4096, 8)\n",
            "\n",
            "--- PHASE 2 COMPLETE! ---\n",
            "We can successfully pre-process a 12-lead ECG into an 8-lead one.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What Phase 3 Does: Engineering the \"Survival\" Label\n",
        "This phase is the most critical part of the project. It's where we translate our simple \"did they die?\" label into a format that a sophisticated survival model can understand.\n",
        "\n",
        "The problem is we can't just ask the model to predict \"yes/no\" for death. A patient who lived for 9 years and then died is very different from a patient who died in 9 days. We need to teach the model about the element of time.\n",
        "\n",
        "To do this, we are replicating the \"discrete-time survival\" method from the Lancet paper.\n",
        "\n",
        "Hereâ€™s the process:\n",
        "\n",
        "We \"Discretize\" Time: Instead of viewing time as a single number (like 800 days), we chop the 10-year follow-up period into 120 small, equal \"intervals\" (like 120 months).\n",
        "\n",
        "We Create y_true (The \"Label\" Array): We create a \"scorecard\" for every single patient that is 120 slots long. Each slot j in the scorecard represents a time interval (e.g., month j).\n",
        "\n",
        "We put a 1 in a slot if the patient survived that interval.\n",
        "\n",
        "We put a 0 in a slot if the patient died in that interval.\n",
        "\n",
        "For example, a patient who died in the 10th interval would have a y_true array that looks like: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...]\n",
        "\n",
        "We Create y_mask (The \"Mask\" Array): This is just as important. We need to tell the model which parts of the scorecard to pay attention to.\n",
        "\n",
        "Many patients in the dataset didn't die; they were just \"lost to follow-up\" after a certain time (e.g., 5 years). We know they survived for 5 years, but we have no idea what happened in year 6.\n",
        "\n",
        "The y_mask array tells the model which slots are \"valid.\" We put a 1 in a slot if we have data for that interval and a 0 if we don't.\n",
        "\n",
        "This mask ensures the model only learns from the data we actually have and isn't punished for \"wrong\" guesses on intervals where we have no information.\n",
        "\n",
        "In summary: Phase 3 converts two simple columns (death and timey) into two detailed arrays (y_true and y_mask) that will teach our model to predict the probability of survival for each month over a 10-year period."
      ],
      "metadata": {
        "id": "gSB4P0juKLMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Survival Time Intervals ---\n",
        "# We'll use 120 intervals, representing 10 years (1 interval per month)\n",
        "N_INTERVALS = 120\n",
        "DAYS_PER_YEAR = 365.25\n",
        "N_YEARS = 10\n",
        "INTERVAL_LENGTH_DAYS = (DAYS_PER_YEAR * N_YEARS) / N_INTERVALS\n",
        "\n",
        "print(f\"--- Survival Model Setup ---\")\n",
        "print(f\"Total intervals: {N_INTERVALS}\")\n",
        "print(f\"Time per interval: {INTERVAL_LENGTH_DAYS:.2f} days (approx 1 month)\")\n",
        "\n",
        "# --- 2. Filter for Relevant Labels ---\n",
        "# The mortality data (death, timey) is only present for the first exam of each patient.\n",
        "# We must drop all the rows where 'death' is NaN (Not a Number).\n",
        "df_survival = df_labels[df_labels['death'].notna()].copy()\n",
        "\n",
        "# Convert 'death' (True/False) to an integer (1/0)\n",
        "df_survival['death'] = df_survival['death'].astype(int)\n",
        "\n",
        "# Convert 'timey' (follow-up time) from days to our new interval index\n",
        "# We use floor() to get the index.\n",
        "# e.g., 50 days / 30.4 days/interval = 1.64 -> interval index 1\n",
        "df_survival['interval_index'] = (df_survival['timey'] / INTERVAL_LENGTH_DAYS).apply(np.floor).astype(int)\n",
        "\n",
        "# Cap the interval at the maximum (119)\n",
        "# If a patient lived 12 years, we only have data up to the 10-year mark (index 119)\n",
        "df_survival['interval_index'] = df_survival['interval_index'].clip(upper=N_INTERVALS - 1)\n",
        "\n",
        "\n",
        "print(f\"\\n--- Label Filtering ---\")\n",
        "print(f\"Original label count: {len(df_labels)}\")\n",
        "print(f\"Survival label count: {len(df_survival)}\")\n",
        "print(\"\\n--- Processed Survival DataFrame (Head) ---\")\n",
        "print(df_survival[['exam_id', 'death', 'timey', 'interval_index']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5u-VLXRJFsT",
        "outputId": "ae8f7107-0b61-4f2c-8a3b-87b54dbfe3d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Survival Model Setup ---\n",
            "Total intervals: 120\n",
            "Time per interval: 30.44 days (approx 1 month)\n",
            "\n",
            "--- Label Filtering ---\n",
            "Original label count: 345779\n",
            "Survival label count: 233647\n",
            "\n",
            "--- Processed Survival DataFrame (Head) ---\n",
            "   exam_id  death     timey  interval_index\n",
            "0  1169160      0  2.098628               0\n",
            "1  2873686      0  6.657529               0\n",
            "2   168405      0  4.282188               0\n",
            "3   271011      0  4.038353               0\n",
            "4   384368      0  3.786298               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the two columns we need from our new DataFrame\n",
        "event_observed = df_survival['death'].values\n",
        "time_observed = df_survival['interval_index'].values\n",
        "\n",
        "# Create empty arrays to hold our new labels\n",
        "# Shape: (number_of_patients, number_of_intervals)\n",
        "y_true = np.zeros((len(df_survival), N_INTERVALS), dtype=np.int32)\n",
        "y_mask = np.zeros((len(df_survival), N_INTERVALS), dtype=np.int32)\n",
        "\n",
        "print(f\"Created empty label arrays with shape: {y_true.shape}\")\n",
        "\n",
        "# Now, loop through each patient and create their specific label arrays\n",
        "for i in range(len(df_survival)):\n",
        "    event = event_observed[i]  # 1 if died, 0 if lived\n",
        "    time = time_observed[i]    # The interval index (e.g., 49)\n",
        "\n",
        "    # 1. Create the 'y_true' label array\n",
        "    # We mark '1' (survived) for all intervals up to their event time\n",
        "    y_true[i, :time] = 1\n",
        "\n",
        "    # If they DIED (event=1), we must mark their final interval as '0' (died)\n",
        "    if event == 1:\n",
        "        y_true[i, time] = 0 # They did NOT survive this interval\n",
        "\n",
        "    # 2. Create the 'y_mask' (attention) array\n",
        "    # The model should pay attention to all intervals UP TO AND INCLUDING the event time.\n",
        "    y_mask[i, :time + 1] = 1\n",
        "\n",
        "print(\"Successfully created y_true and y_mask arrays.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Robust Verification ---\n",
        "print(\"\\n--- Robust Verification ---\")\n",
        "\n",
        "# 1. Find the first patient who DIED (event=1)\n",
        "try:\n",
        "    patient_died_idx = np.where(event_observed == 1)[0][0]\n",
        "    died_time = time_observed[patient_died_idx]\n",
        "\n",
        "    print(f\"\\nFound a patient who DIED (event=1) at interval {died_time} (index {patient_died_idx}).\")\n",
        "    print(\"Showing intervals around their event time:\")\n",
        "    # Slicing to show 5 intervals before and 5 after\n",
        "    print(f\"y_true (Label): {y_true[patient_died_idx, max(0, died_time-5) : died_time+5]}\")\n",
        "    print(f\"y_mask (Mask): {y_mask[patient_died_idx, max(0, died_time-5) : died_time+5]}\")\n",
        "    # The 'y_true' should end with a '0'\n",
        "    # The 'y_mask' should end with a '1' at the same spot\n",
        "\n",
        "except IndexError:\n",
        "    print(\"\\nCould not find any patients who died in the dataset (this is unlikely).\")\n",
        "\n",
        "\n",
        "# 2. Find the first patient who LIVED (event=0)\n",
        "try:\n",
        "    patient_lived_idx = np.where(event_observed == 0)[0][0]\n",
        "    lived_time = time_observed[patient_lived_idx]\n",
        "\n",
        "    print(f\"\\nFound a patient who LIVED (event=0) at interval {lived_time} (index {patient_lived_idx}).\")\n",
        "    print(\"Showing intervals around their event time:\")\n",
        "    # Slicing to show 5 intervals before and 5 after\n",
        "    print(f\"y_true (Label): {y_true[patient_lived_idx, max(0, lived_time-5) : lived_time+5]}\")\n",
        "    print(f\"y_mask (Mask): {y_mask[patient_lived_idx, max(0, lived_time-5) : lived_time+5]}\")\n",
        "    # The 'y_true' should be all '1's\n",
        "    # The 'y_mask' should end with a '1' at the same spot as 'y_true'\n",
        "\n",
        "except IndexError:\n",
        "    print(\"\\nCould not find any patients who lived/were censored in the dataset (this is unlikely).\")\n",
        "\n",
        "\n",
        "print(\"\\n--- PHASE 3 COMPLETE! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzoDxfztJYMu",
        "outputId": "6b777c41-2724-49ce-8416-921646eec3d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created empty label arrays with shape: (233647, 120)\n",
            "Successfully created y_true and y_mask arrays.\n",
            "\n",
            "--- Robust Verification ---\n",
            "\n",
            "Found a patient who DIED (event=1) at interval 0 (index 29).\n",
            "Showing intervals around their event time:\n",
            "y_true (Label): [0 0 0 0 0]\n",
            "y_mask (Mask): [1 0 0 0 0]\n",
            "\n",
            "Found a patient who LIVED (event=0) at interval 0 (index 0).\n",
            "Showing intervals around their event time:\n",
            "y_true (Label): [0 0 0 0 0]\n",
            "y_mask (Mask): [1 0 0 0 0]\n",
            "\n",
            "--- PHASE 3 COMPLETE! ---\n"
          ]
        }
      ]
    }
  ]
}